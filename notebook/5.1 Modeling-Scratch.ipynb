{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca04fce3",
   "metadata": {
    "id": "ca04fce3"
   },
   "source": [
    "# 5.1 Modeling - Logistic Regression Scratch & Time Execuation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d20e20",
   "metadata": {
    "id": "04d20e20"
   },
   "source": [
    "This notebook focuses on building and evaluating models for sentiment analysis using Logistic Regression and Lexicon Based. The process includes loading the preprocessed data, splitting it into training and test sets, and vectorizing the text data using TF-IDF. We then train a logistic regression model on the training data and evaluate its performance using various metrics. The notebook concludes with saving the trained model, making it ready for deployment in future applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6d7650",
   "metadata": {
    "id": "ae6d7650"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import psutil\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1LRXf4_8mPpO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LRXf4_8mPpO",
    "outputId": "d27edf2a-b586-4d97-9dd5-cec77081b7d2"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aebec89",
   "metadata": {
    "id": "0aebec89"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13d60af-a2b2-4fe3-95ae-aaf1374ac810",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "d13d60af-a2b2-4fe3-95ae-aaf1374ac810",
    "outputId": "cc8084fa-f23b-4c18-cd80-d8d327e5e9bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>Komentar</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Score</th>\n",
       "      <th>month_year</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>final_text</th>\n",
       "      <th>token</th>\n",
       "      <th>stop_text</th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-08 04:10:06+00:00</td>\n",
       "      <td>@ikanmokpoo mjb, mau transaksi apa Kak? Aku tr...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5.016.244.649.887.080</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>mjb transaksi kak transaksi bayar pake qris td...</td>\n",
       "      <td>mjb transaksi kak transaksi bayar pakai qris t...</td>\n",
       "      <td>['mjb', 'transaksi', 'kak', 'transaksi', 'baya...</td>\n",
       "      <td>['transaksi', 'transaksi', 'bayar', 'qris', 'a...</td>\n",
       "      <td>transaksi transaksi bayar qris aman lancar jaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-05 10:48:34+00:00</td>\n",
       "      <td>@BNICustomerCare ini kenapa dari dulu setiap m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>989.467.442.035.675</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>transaksi qris via bni ga ya min scan barcode ...</td>\n",
       "      <td>transaksi qris melalui bni tidak ya minimal sc...</td>\n",
       "      <td>['transaksi', 'qris', 'melalui', 'bni', 'tidak...</td>\n",
       "      <td>['transaksi', 'qris', 'minimal', 'scan', 'barc...</td>\n",
       "      <td>transaksi qris minimal scan barcode otomatis c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-17 04:21:57+00:00</td>\n",
       "      <td>@tanyakanrl Keuntungannya praktis, tinggal swi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>8.306.553.959.846.490</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>keuntunganya praktis tingal swipe up homescren...</td>\n",
       "      <td>keuntunganya praktis tinggal swipe up homescre...</td>\n",
       "      <td>['keuntunganya', 'praktis', 'tinggal', 'swipe'...</td>\n",
       "      <td>['keuntunganya', 'praktis', 'tinggal', 'swipe'...</td>\n",
       "      <td>keuntunganya praktis tinggal swipe homescrenlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-03 16:20:59+00:00</td>\n",
       "      <td>@leeehovo @discountfess mau tanya kak, di pert...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9.959.661.960.601.800</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>kak pertamina bayar mengunakan qris nga</td>\n",
       "      <td>kak pertamina bayar mengunakan qris tidak</td>\n",
       "      <td>['kak', 'pertamina', 'bayar', 'mengunakan', 'q...</td>\n",
       "      <td>['pertamina', 'bayar', 'mengunakan', 'qris']</td>\n",
       "      <td>pertamina bayar mengunakan qris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-08-21 11:39:04+00:00</td>\n",
       "      <td>Udah 4x gw transaksi di alfa bahkan alfa yg ad...</td>\n",
       "      <td>negative</td>\n",
       "      <td>996.809.422.969.818</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>udah gw transaksi alfa alfa yg beda kota gagal...</td>\n",
       "      <td>sudah saya transaksi alfa alfa yang beda kota ...</td>\n",
       "      <td>['sudah', 'saya', 'transaksi', 'alfa', 'alfa',...</td>\n",
       "      <td>['transaksi', 'alfa', 'alfa', 'beda', 'kota', ...</td>\n",
       "      <td>transaksi alfa alfa beda kota gagal ros qris m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>2024-06-24 04:55:11+00:00</td>\n",
       "      <td>haii haii kyu ada saldo receh nominal rahasia ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9.753.036.499.023.430</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>hai kyu saldo receh nominal rahasia ba qris ru...</td>\n",
       "      <td>hai ada saldo receh nominal rahasia akun bisni...</td>\n",
       "      <td>['hai', 'ada', 'saldo', 'receh', 'nominal', 'r...</td>\n",
       "      <td>['nominal', 'rahasia', 'akun', 'bisnis', 'qris...</td>\n",
       "      <td>nominal rahasia akun bisnis qris rulesnya twet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>2024-06-24 06:10:37+00:00</td>\n",
       "      <td>Banyak orang gatau kalau nyari duit itu segamp...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>8.691.744.804.382.320</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>orang gatau nyari duit segampang main slot gac...</td>\n",
       "      <td>orang tidak tahu mencari uang segampang main s...</td>\n",
       "      <td>['orang', 'tidak', 'tahu', 'mencari', 'uang', ...</td>\n",
       "      <td>['orang', 'mencari', 'uang', 'segampang', 'mai...</td>\n",
       "      <td>orang cari uang gampang main gacor paris modal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>2024-06-24 06:23:05+00:00</td>\n",
       "      <td>Di aku ready nih kak! Murce murce all e-wallet...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9.926.472.902.297.970</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>ready nih kak murce al ewalet qris dm or wa</td>\n",
       "      <td>siap ini kak murah al ewalet qris direct messa...</td>\n",
       "      <td>['siap', 'ini', 'kak', 'murah', 'al', 'ewalet'...</td>\n",
       "      <td>['murah', 'al', 'ewalet', 'qris', 'direct', 'm...</td>\n",
       "      <td>murah al ewalet qris direct message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>2024-06-24 07:09:20+00:00</td>\n",
       "      <td>mau netflix 1 bulan yg bs qris #zonauang</td>\n",
       "      <td>neutral</td>\n",
       "      <td>99.673.330.783.844</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>netflix yg bs qris</td>\n",
       "      <td>netflix yang bisa qris</td>\n",
       "      <td>['netflix', 'yang', 'bisa', 'qris']</td>\n",
       "      <td>['netflix', 'qris']</td>\n",
       "      <td>netflix qris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>2024-06-24 07:19:41+00:00</td>\n",
       "      <td>giveaway saldo receh buat BA only yang punya Q...</td>\n",
       "      <td>negative</td>\n",
       "      <td>5.737.491.846.084.590</td>\n",
       "      <td>2024-06</td>\n",
       "      <td>giveaway saldo receh ba only qris rt rt pined ...</td>\n",
       "      <td>giveaway saldo receh akun bisnis hanya qris rt...</td>\n",
       "      <td>['giveaway', 'saldo', 'receh', 'akun', 'bisnis...</td>\n",
       "      <td>['akun', 'bisnis', 'qris', 'pined', 'mutualan'...</td>\n",
       "      <td>akun bisnis qris pined mutualan cepat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7714 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at  \\\n",
       "0     2023-03-08 04:10:06+00:00   \n",
       "1     2023-03-05 10:48:34+00:00   \n",
       "2     2023-03-17 04:21:57+00:00   \n",
       "3     2023-03-03 16:20:59+00:00   \n",
       "4     2023-08-21 11:39:04+00:00   \n",
       "...                         ...   \n",
       "7709  2024-06-24 04:55:11+00:00   \n",
       "7710  2024-06-24 06:10:37+00:00   \n",
       "7711  2024-06-24 06:23:05+00:00   \n",
       "7712  2024-06-24 07:09:20+00:00   \n",
       "7713  2024-06-24 07:19:41+00:00   \n",
       "\n",
       "                                               Komentar Sentiment  \\\n",
       "0     @ikanmokpoo mjb, mau transaksi apa Kak? Aku tr...  positive   \n",
       "1     @BNICustomerCare ini kenapa dari dulu setiap m...  negative   \n",
       "2     @tanyakanrl Keuntungannya praktis, tinggal swi...  positive   \n",
       "3     @leeehovo @discountfess mau tanya kak, di pert...   neutral   \n",
       "4     Udah 4x gw transaksi di alfa bahkan alfa yg ad...  negative   \n",
       "...                                                 ...       ...   \n",
       "7709  haii haii kyu ada saldo receh nominal rahasia ...   neutral   \n",
       "7710  Banyak orang gatau kalau nyari duit itu segamp...   neutral   \n",
       "7711  Di aku ready nih kak! Murce murce all e-wallet...   neutral   \n",
       "7712           mau netflix 1 bulan yg bs qris #zonauang   neutral   \n",
       "7713  giveaway saldo receh buat BA only yang punya Q...  negative   \n",
       "\n",
       "                      Score month_year  \\\n",
       "0     5.016.244.649.887.080    2023-03   \n",
       "1       989.467.442.035.675    2023-03   \n",
       "2     8.306.553.959.846.490    2023-03   \n",
       "3     9.959.661.960.601.800    2023-03   \n",
       "4       996.809.422.969.818    2023-08   \n",
       "...                     ...        ...   \n",
       "7709  9.753.036.499.023.430    2024-06   \n",
       "7710  8.691.744.804.382.320    2024-06   \n",
       "7711  9.926.472.902.297.970    2024-06   \n",
       "7712     99.673.330.783.844    2024-06   \n",
       "7713  5.737.491.846.084.590    2024-06   \n",
       "\n",
       "                                             clean_text  \\\n",
       "0     mjb transaksi kak transaksi bayar pake qris td...   \n",
       "1     transaksi qris via bni ga ya min scan barcode ...   \n",
       "2     keuntunganya praktis tingal swipe up homescren...   \n",
       "3               kak pertamina bayar mengunakan qris nga   \n",
       "4     udah gw transaksi alfa alfa yg beda kota gagal...   \n",
       "...                                                 ...   \n",
       "7709  hai kyu saldo receh nominal rahasia ba qris ru...   \n",
       "7710  orang gatau nyari duit segampang main slot gac...   \n",
       "7711        ready nih kak murce al ewalet qris dm or wa   \n",
       "7712                                 netflix yg bs qris   \n",
       "7713  giveaway saldo receh ba only qris rt rt pined ...   \n",
       "\n",
       "                                             final_text  \\\n",
       "0     mjb transaksi kak transaksi bayar pakai qris t...   \n",
       "1     transaksi qris melalui bni tidak ya minimal sc...   \n",
       "2     keuntunganya praktis tinggal swipe up homescre...   \n",
       "3             kak pertamina bayar mengunakan qris tidak   \n",
       "4     sudah saya transaksi alfa alfa yang beda kota ...   \n",
       "...                                                 ...   \n",
       "7709  hai ada saldo receh nominal rahasia akun bisni...   \n",
       "7710  orang tidak tahu mencari uang segampang main s...   \n",
       "7711  siap ini kak murah al ewalet qris direct messa...   \n",
       "7712                             netflix yang bisa qris   \n",
       "7713  giveaway saldo receh akun bisnis hanya qris rt...   \n",
       "\n",
       "                                                  token  \\\n",
       "0     ['mjb', 'transaksi', 'kak', 'transaksi', 'baya...   \n",
       "1     ['transaksi', 'qris', 'melalui', 'bni', 'tidak...   \n",
       "2     ['keuntunganya', 'praktis', 'tinggal', 'swipe'...   \n",
       "3     ['kak', 'pertamina', 'bayar', 'mengunakan', 'q...   \n",
       "4     ['sudah', 'saya', 'transaksi', 'alfa', 'alfa',...   \n",
       "...                                                 ...   \n",
       "7709  ['hai', 'ada', 'saldo', 'receh', 'nominal', 'r...   \n",
       "7710  ['orang', 'tidak', 'tahu', 'mencari', 'uang', ...   \n",
       "7711  ['siap', 'ini', 'kak', 'murah', 'al', 'ewalet'...   \n",
       "7712                ['netflix', 'yang', 'bisa', 'qris']   \n",
       "7713  ['giveaway', 'saldo', 'receh', 'akun', 'bisnis...   \n",
       "\n",
       "                                              stop_text  \\\n",
       "0     ['transaksi', 'transaksi', 'bayar', 'qris', 'a...   \n",
       "1     ['transaksi', 'qris', 'minimal', 'scan', 'barc...   \n",
       "2     ['keuntunganya', 'praktis', 'tinggal', 'swipe'...   \n",
       "3          ['pertamina', 'bayar', 'mengunakan', 'qris']   \n",
       "4     ['transaksi', 'alfa', 'alfa', 'beda', 'kota', ...   \n",
       "...                                                 ...   \n",
       "7709  ['nominal', 'rahasia', 'akun', 'bisnis', 'qris...   \n",
       "7710  ['orang', 'mencari', 'uang', 'segampang', 'mai...   \n",
       "7711  ['murah', 'al', 'ewalet', 'qris', 'direct', 'm...   \n",
       "7712                                ['netflix', 'qris']   \n",
       "7713  ['akun', 'bisnis', 'qris', 'pined', 'mutualan'...   \n",
       "\n",
       "                                              stem_text  \n",
       "0       transaksi transaksi bayar qris aman lancar jaya  \n",
       "1     transaksi qris minimal scan barcode otomatis c...  \n",
       "2     keuntunganya praktis tinggal swipe homescrenlo...  \n",
       "3                       pertamina bayar mengunakan qris  \n",
       "4     transaksi alfa alfa beda kota gagal ros qris m...  \n",
       "...                                                 ...  \n",
       "7709  nominal rahasia akun bisnis qris rulesnya twet...  \n",
       "7710  orang cari uang gampang main gacor paris modal...  \n",
       "7711                murah al ewalet qris direct message  \n",
       "7712                                       netflix qris  \n",
       "7713              akun bisnis qris pined mutualan cepat  \n",
       "\n",
       "[7714 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataframe\n",
    "df = pd.read_csv('preprocessed_final.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139496ea-1a8a-462d-baae-39ff29b2a4cc",
   "metadata": {
    "id": "139496ea-1a8a-462d-baae-39ff29b2a4cc"
   },
   "outputs": [],
   "source": [
    "data = df[['stem_text', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84feed78-c895-457d-b8c1-fb4bd8f103c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "84feed78-c895-457d-b8c1-fb4bd8f103c4",
    "outputId": "0d3e9b1f-14a6-4f69-f0a1-f00ab86542ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem_text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transaksi transaksi bayar qris aman lancar jaya</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transaksi qris minimal scan barcode otomatis c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keuntunganya praktis tinggal swipe homescrenlo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pertamina bayar mengunakan qris</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transaksi alfa alfa beda kota gagal ros qris m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7709</th>\n",
       "      <td>nominal rahasia akun bisnis qris rulesnya twet...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7710</th>\n",
       "      <td>orang cari uang gampang main gacor paris modal...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>murah al ewalet qris direct message</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>netflix qris</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>akun bisnis qris pined mutualan cepat</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7714 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              stem_text Sentiment\n",
       "0       transaksi transaksi bayar qris aman lancar jaya  positive\n",
       "1     transaksi qris minimal scan barcode otomatis c...  negative\n",
       "2     keuntunganya praktis tinggal swipe homescrenlo...  positive\n",
       "3                       pertamina bayar mengunakan qris   neutral\n",
       "4     transaksi alfa alfa beda kota gagal ros qris m...  negative\n",
       "...                                                 ...       ...\n",
       "7709  nominal rahasia akun bisnis qris rulesnya twet...   neutral\n",
       "7710  orang cari uang gampang main gacor paris modal...   neutral\n",
       "7711                murah al ewalet qris direct message   neutral\n",
       "7712                                       netflix qris   neutral\n",
       "7713              akun bisnis qris pined mutualan cepat  negative\n",
       "\n",
       "[7714 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe4e0e3-75b9-42f3-93c9-ca0d8a4ae6be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fe4e0e3-75b9-42f3-93c9-ca0d8a4ae6be",
    "outputId": "460f7a6c-36df-44e6-a12f-179643cdc135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     5912\n",
       "negative    1031\n",
       "positive     771\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49_Fud_QQo4v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49_Fud_QQo4v",
    "outputId": "388e9c1f-32f1-4f4f-d8c5-95e0b3a8c841"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nab\\AppData\\Local\\Temp\\ipykernel_10720\\2133464409.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Sentiment'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['Sentiment'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff8348",
   "metadata": {
    "id": "40ff8348"
   },
   "source": [
    "## Changing sentiment values into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eab8915",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eab8915",
    "outputId": "8819fbd2-8a51-4ee7-fcf7-c7e723a630bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nab\\AppData\\Local\\Temp\\ipykernel_10720\\3657538082.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Sentiment'] = data['Sentiment'].replace({'positive': 0, 'neutral': 1, 'negative': 2}).astype(int)\n",
      "C:\\Users\\Nab\\AppData\\Local\\Temp\\ipykernel_10720\\3657538082.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'Sentiment'] = data['Sentiment'].replace({'positive': 0, 'neutral': 1, 'negative': 2}).astype(int)\n"
     ]
    }
   ],
   "source": [
    "data['Sentiment'] = data['Sentiment'].replace({'positive': 0, 'neutral': 1, 'negative': 2}).astype(int)\n",
    "# Use .loc to modify the DataFrame\n",
    "data.loc[:, 'Sentiment'] = data['Sentiment'].replace({'positive': 0, 'neutral': 1, 'negative': 2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3Ag3LP7TIbs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3Ag3LP7TIbs",
    "outputId": "debf9178-4147-4c81-9d67-89c383399d31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nab\\AppData\\Local\\Temp\\ipykernel_10720\\2477820184.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['stem_text'] = data['stem_text'].fillna('')\n"
     ]
    }
   ],
   "source": [
    "data['stem_text'] = data['stem_text'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bda765",
   "metadata": {
    "id": "47bda765"
   },
   "source": [
    "## Split the text into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021a58da",
   "metadata": {
    "id": "021a58da"
   },
   "outputs": [],
   "source": [
    "X = data['stem_text']\n",
    "y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "711feb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         transaksi transaksi bayar qris aman lancar jaya\n",
       "1       transaksi qris minimal scan barcode otomatis c...\n",
       "2       keuntunganya praktis tinggal swipe homescrenlo...\n",
       "3                         pertamina bayar mengunakan qris\n",
       "4       transaksi alfa alfa beda kota gagal ros qris m...\n",
       "                              ...                        \n",
       "7709    nominal rahasia akun bisnis qris rulesnya twet...\n",
       "7710    orang cari uang gampang main gacor paris modal...\n",
       "7711                  murah al ewalet qris direct message\n",
       "7712                                         netflix qris\n",
       "7713                akun bisnis qris pined mutualan cepat\n",
       "Name: stem_text, Length: 7714, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OynIgrFuUCZR",
   "metadata": {
    "id": "OynIgrFuUCZR"
   },
   "source": [
    "# Modeling Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf1c9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionOvR:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.models = []\n",
    "        self.scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred, class_weights):\n",
    "        epsilon = 1e-9\n",
    "        y1 = y_true * np.log(y_pred + epsilon)\n",
    "        y2 = (1 - y_true) * np.log(1 - y_pred + epsilon)\n",
    "        return -np.mean(class_weights * (y1 + y2))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Normalize the data\n",
    "        X = self.scaler.fit_transform(X).toarray()  # Convert to dense array\n",
    "\n",
    "        # Train a separate model for each class (One-vs-Rest)\n",
    "        unique_classes = np.unique(y)\n",
    "        for cls in unique_classes:\n",
    "            y_binary = np.where(y == cls, 1, 0)  # Create binary labels for the current class\n",
    "\n",
    "            # Initialize parameters for the current class\n",
    "            weights = np.random.randn(n_features) * 0.01\n",
    "            bias = 0\n",
    "\n",
    "            # Calculate class weights\n",
    "            class_counts = np.bincount(y_binary)\n",
    "            total_samples = len(y_binary)\n",
    "            class_weights = {0: total_samples / class_counts[0], 1: total_samples / class_counts[1]}\n",
    "\n",
    "            # Gradient descent for the current class\n",
    "            for _ in range(self.n_iters):\n",
    "                z = X.dot(weights) + bias\n",
    "                A = self._sigmoid(z)\n",
    "                weighted_loss = self.compute_loss(y_binary, A, np.array([class_weights[label] for label in y_binary]))\n",
    "                dz = (A - y_binary) * np.array([class_weights[label] for label in y_binary])\n",
    "                dw = (1 / n_samples) * X.T.dot(dz)\n",
    "                db = (1 / n_samples) * np.sum(dz)\n",
    "                weights -= self.lr * dw\n",
    "                bias -= self.lr * db\n",
    "\n",
    "            # Store the trained weights and bias for the current class\n",
    "            self.models.append((weights, bias))\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Normalize the data using the fitted scaler\n",
    "        X = self.scaler.transform(X).toarray()  # Convert to dense array\n",
    "\n",
    "        # Compute predictions for each class and choose the class with the highest probability\n",
    "        predictions = []\n",
    "        for weights, bias in self.models:\n",
    "            z = X.dot(weights) + bias\n",
    "            A = self._sigmoid(z)\n",
    "            predictions.append(A)\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "        y_predicted_cls = np.argmax(predictions, axis=0)\n",
    "        return y_predicted_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e60c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Calculate Memory Usage\n",
    "def measure_resources():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    cpu_usage = process.cpu_percent(interval=1)\n",
    "    memory_usage = process.memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "    return cpu_usage, memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffd4fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waktu eksekusi training: 79.17750525474548 detik\n",
      "Penggunaan CPU untuk training: 0.0 %\n",
      "Penggunaan Memory untuk training: 2.16015625 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert the text data to TF-IDF features\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.1, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegressionOvR(learning_rate=0.01, n_iters=500)\n",
    "\n",
    "# Measure resources before training\n",
    "cpu_before, memory_before = measure_resources()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Measure resources after training\n",
    "cpu_after, memory_after = measure_resources()\n",
    "\n",
    "# Calculate resource usage\n",
    "training_cpu_usage = cpu_after - cpu_before\n",
    "training_memory_usage = memory_after - memory_before\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"Waktu eksekusi training: {training_time} detik\")\n",
    "print(f\"Penggunaan CPU untuk training: {training_cpu_usage} %\")\n",
    "print(f\"Penggunaan Memory untuk training: {training_memory_usage} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d93b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.61      0.51        79\n",
      "           1       0.89      0.83      0.86       597\n",
      "           2       0.48      0.55      0.51        96\n",
      "\n",
      "    accuracy                           0.77       772\n",
      "   macro avg       0.61      0.66      0.63       772\n",
      "weighted avg       0.80      0.77      0.78       772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "predictions=model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d901581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Iterations: 500, Accuracy: 71.11398963730569%\n",
      "Learning Rate: 0.001, Iterations: 1000, Accuracy: 74.22279792746113%\n",
      "Learning Rate: 0.001, Iterations: 2000, Accuracy: 78.75647668393782%\n",
      "Learning Rate: 0.01, Iterations: 500, Accuracy: 78.10880829015544%\n",
      "Learning Rate: 0.01, Iterations: 1000, Accuracy: 79.40414507772022%\n",
      "Learning Rate: 0.01, Iterations: 2000, Accuracy: 78.23834196891191%\n",
      "Learning Rate: 0.1, Iterations: 500, Accuracy: 78.49740932642487%\n",
      "Learning Rate: 0.1, Iterations: 1000, Accuracy: 76.81347150259067%\n",
      "Learning Rate: 0.1, Iterations: 2000, Accuracy: 77.07253886010362%\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.01, 'n_iters': 1000}\n",
      "Best Accuracy: 79.40414507772022%\n"
     ]
    }
   ],
   "source": [
    "# Parameter grids to try\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "iterations = [500, 1000, 2000]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for n_iter in iterations:\n",
    "        model = LogisticRegressionOvR(learning_rate=lr, n_iters=n_iter)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = np.mean(predictions == y_test) * 100\n",
    "        print(f\"Learning Rate: {lr}, Iterations: {n_iter}, Accuracy: {accuracy}%\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'learning_rate': lr, 'n_iters': n_iter}\n",
    "\n",
    "print(f\"\\nBest Parameters: {best_params}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "259e0155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 1 1 1 1 2 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 2 1 2 1 1 1 0\n",
      " 1 1 2 1 1 0 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 2 1 1 2 1 0 1 1 1 1 1 1 2 0 0 1 1 1 1 1 1 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1\n",
      " 0 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 2 1 1 2 1 1 0 1 1 1 2 1\n",
      " 0 1 1 1 2 1 1 1 2 2 1 1 1 1 2 2 1 2 2 1 1 1 2 1 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 2 0 1 2 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 2 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 1 2 1\n",
      " 1 1 1 1 2 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1\n",
      " 1 1 1 1 1 1 2 1 1 1 0 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 2 0 1 1 2 2 2 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0\n",
      " 1 0 2 0 1 1 2 2 2 1 1 1 2 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 0 2 1 1 1 1 1 2 1 1 1 1 0 1 1 1 1 1 1 1 2 2 1 1 1 0 0 2 1 2 0 1 1 0 1 1 1\n",
      " 1 1 2 1 1 1 2 0 1 1 1 1 0 1 1 2 1 1 1 2 1 1 2 0 1 0 1 2 1 0 1 0 1 1 1 1 1\n",
      " 2 1 1 0 1 1 1 2 2 1 0 1 2 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 2 1 2 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 0 0 1 2 1 1 2 1 1 0 2 2 2 1 1 1 1 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 0 1 0 0 0 1 1 1 2 1 2\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 2 0 0 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2\n",
      " 2 1 1 1 2 2 1 1 1 1 1 1 0 0 2 1 1 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1 2 1 1 1 0 1 2 0 1 2 2 0 1 1 1 0 2 0 0 1 1 1 2 1 1 1 1 1 1 1]\n",
      "Accuracy: 77.07%\n",
      "Waktu eksekusi prediksi: 0.06118059158325195 detik\n"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Predicting the data\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = np.mean(predictions == y_test) * 100\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate execution time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Waktu eksekusi prediksi: {training_time} detik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5cf439",
   "metadata": {
    "id": "OynIgrFuUCZR"
   },
   "source": [
    "# Lexicon Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be34b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lexicon data\n",
    "def load_lexicon(filepath):\n",
    "    lexicon = {}\n",
    "    with open(filepath, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            lexicon[row[0]] = int(row[1])\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95208c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "lexicon_positive = load_lexicon('lexicon_positive_ver1.csv')\n",
    "lexicon_negative = load_lexicon('lexicon_negative_ver1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a4c9466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_lexicon_indonesia(text):\n",
    "  score = 0\n",
    "  for word_pos in text:\n",
    "    if (word_pos in lexicon_positive):\n",
    "      score = score + lexicon_positive[word_pos]\n",
    "  for word_neg in text:\n",
    "    if (word_neg in lexicon_negative):\n",
    "      score = score + lexicon_negative[word_neg]\n",
    "  polarity=''\n",
    "  if (score > 0):\n",
    "    polarity = 'positive'\n",
    "  elif (score < 0):\n",
    "    polarity = 'negative'\n",
    "  else:\n",
    "    polarity = 'neutral'\n",
    "\n",
    "  return score, polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c5de08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waktu eksekusi Lexicon-based: 1.084197759628296 detik\n",
      "Penggunaan CPU untuk Lexicon-based: 0.0 %\n",
      "Penggunaan Memory untuk Lexicon-based: 0.58984375 MB\n",
      "negative    5583\n",
      "positive    1604\n",
      "neutral      527\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Measure time and resources for Lexicon-based method\n",
    "start_time = time.time()\n",
    "cpu_before, memory_before = measure_resources()\n",
    "df['prepos_text'] = df['stem_text'].str.split()\n",
    "df['prepos_text'] = df['prepos_text'].fillna('')\n",
    "results = df['prepos_text'].apply(sentiment_analysis_lexicon_indonesia)\n",
    "results = list(zip(*results))\n",
    "df['polarity_score'] = results[0]\n",
    "df['polarity'] = results[1]\n",
    "end_time = time.time()\n",
    "cpu_after, memory_after = measure_resources()\n",
    "lexicon_time = end_time - start_time\n",
    "lexicon_cpu_usage = cpu_after - cpu_before\n",
    "lexicon_memory_usage = memory_after - memory_before\n",
    "\n",
    "print(f\"Waktu eksekusi Lexicon-based: {lexicon_time} detik\")\n",
    "print(f\"Penggunaan CPU untuk Lexicon-based: {lexicon_cpu_usage} %\")\n",
    "print(f\"Penggunaan Memory untuk Lexicon-based: {lexicon_memory_usage} MB\")\n",
    "print(df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa04ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
